Conference: dotscale-2016
Tags: Scalability
Filmed: 2016-05-25
Author: seanowen
Image: https://farm2.staticflickr.com/1597/26659173745_c13e040451_k_d.jpg
Title: Scaling Learning on Apache Spark
Curator: sylvinus
Category: Backend
Summary: Scaling up machine learning techniques to keep pace with "big data" is its own interesting engineering problem. Recently, Apache Spark has become a popular framework for large-scale ML. Sean introduces the intuition behind modern large-scale recommenders and highlights four ways ML algorithms are engineered to scale.
Slides: https://drive.google.com/open?id=0B_hfrkaWlLi4YnVhckExbFFZY1k
Video: https://www.youtube.com/watch?v=MvyZYr9yKzM
Template: talk
Date: 2016-05-10 10:47:46
Status: draft


Additional resources:
- Spark documentation: [http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html#collaborative-filtering](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html#collaborative-filtering)
- (Old) introductory blog post discussing Spark and ALS:
[http://blog.cloudera.com/blog/2014/03/why-apache-spark-is-a-crossover-hit-for-data-scientists/](http://blog.cloudera.com/blog/2014/03/why-apache-spark-is-a-crossover-hit-for-data-scientists/)
- Plug for "Advanced Analytics with Spark", which covers Spark and ALS in Chapter 3:
[http://shop.oreilly.com/product/0636920035091.do](http://shop.oreilly.com/product/0636920035091.do)
- Relevant example code to accompany that chapter 3:
[https://github.com/sryza/aas/tree/master/ch03-recommender](https://github.com/sryza/aas/tree/master/ch03-recommender)